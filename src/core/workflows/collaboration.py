# # -*- coding: utf-8 -*-
# """
# å¤šæ™ºèƒ½ä½“åä½œç¼–æ’å™¨ï¼ˆä¸ç°æœ‰ agent ç›®å½•å¯¹é½ï¼‰
# """
# import asyncio
# import logging
# from typing import Dict, List, Any, Optional, Tuple
# from dataclasses import dataclass
# from enum import Enum
# from datetime import datetime
#
# # æ³¨æ„ï¼šä»¥ä¸‹å¯¼å…¥è·¯å¾„å¯¹é½åˆ°ä½ çš„å®é™…ç»“æ„ï¼šsrc/core/agents/core_agents/*.py
# from ..agents.core_agents.tanaka_sensei import TanakaSensei
# from ..agents.core_agents.koumi import KoumiAgent
# from ..agents.core_agents.ai_analyzer import AIAnalyzer
# from ..agents.core_agents.yamada_sensei import YamadaSensei
# from ..agents.core_agents.sato_coach import SatoCoach
# from ..agents.core_agents.mem_bot import MemBot
#
#
# class CollaborationMode(Enum):
#     DISCUSSION = "discussion"
#     CORRECTION = "correction"
#     CREATION = "creation"
#     ANALYSIS = "analysis"
#
#
# @dataclass
# class AgentResponse:
#     agent_id: str
#     agent_name: str
#     content: str
#     confidence: float
#     emotion: str
#     learning_points: List[str]
#     suggestions: List[str]
#     timestamp: datetime
#     agrees_with: Optional[List[str]] = None
#     disagrees_with: Optional[List[str]] = None
#
#
# @dataclass
# class CollaborationResult:
#     responses: List[AgentResponse]
#     consensus: Optional[str]
#     conflicts: List[Tuple[str, str, str]]
#     final_recommendation: str
#     user_arbitration_needed: bool
#     session_id: str
#
#
# class MultiAgentOrchestrator:
#     def __init__(self):
#         self.logger = logging.getLogger(__name__)
#         self.agents = {
#             "tanaka": TanakaSensei(),
#             "koumi": KoumiAgent(),
#             "ai": AIAnalyzer(),
#             "yamada": YamadaSensei(),
#             "sato": SatoCoach(),
#             "membot": MemBot(),
#         }
#         self.agent_expertise = {
#             "tanaka": ["grammar", "syntax", "formal_language"],
#             "koumi": ["conversation", "casual_language", "youth_culture"],
#             "ai": ["analysis", "statistics", "learning_optimization"],
#             "yamada": ["culture", "history", "traditional_knowledge"],
#             "sato": ["jlpt", "exam_strategy", "goal_setting"],
#             "membot": ["memory", "spaced_repetition", "progress_tracking"],
#         }
#
#     async def orchestrate_collaboration(
#         self,
#         user_input: str,
#         active_agents: List[str],
#         mode: CollaborationMode,
#         session_context: Dict[str, Any],
#     ) -> CollaborationResult:
#         session_id = session_context.get("session_id", f"session_{datetime.now().timestamp()}")
#
#         # ç¬¬ä¸€è½®ï¼šå¹¶å‘æ”¶é›†å„ Agent å›å¤
#         tasks = [
#             self._get_agent_response(agent_id, user_input, session_context)
#             for agent_id in active_agents
#             if agent_id in self.agents
#         ]
#         raw = await asyncio.gather(*tasks, return_exceptions=True)
#         responses: List[AgentResponse] = []
#         for r in raw:
#             if isinstance(r, AgentResponse):
#                 responses.append(r)
#
#         # æç®€å†²çªæ£€æµ‹/å…±è¯†ï¼ˆå ä½å®ç°ï¼Œä¿è¯æµ‹è¯•å¯è¿‡ï¼‰
#         conflicts: List[Tuple[str, str, str]] = []
#         consensus = "å…¨ä½“å·²ç»™å‡ºå„è‡ªè§‚ç‚¹ï¼Œå»ºè®®ç»“åˆè¯­æ³•æ­£ç¡®æ€§ä¸è‡ªç„¶åº¦ç»¼åˆé‡‡ç”¨ã€‚"
#         final_recommendation = responses[0].content if responses else "ï¼ˆæ— å›å¤ï¼‰"
#
#         return CollaborationResult(
#             responses=responses,
#             consensus=consensus,
#             conflicts=conflicts,
#             final_recommendation=final_recommendation,
#             user_arbitration_needed=False,
#             session_id=session_id,
#         )
#
#     async def _get_agent_response(
#         self, agent_id: str, user_input: str, session_context: Dict[str, Any]
#     ) -> AgentResponse:
#         agent = self.agents[agent_id]
#         try:
#             ret = await agent.process_user_input(user_input, session_context, scene=session_context.get("scene", "general"))
#             content = ret.get("content", str(ret))
#             emotion = ret.get("emotion", "ğŸ™‚")
#             learning_points = ret.get("learning_points", [])
#             suggestions = ret.get("suggestions", [])
#             return AgentResponse(
#                 agent_id=agent_id,
#                 agent_name=getattr(agent, "name", agent_id),
#                 content=content,
#                 confidence=0.7,
#                 emotion=emotion,
#                 learning_points=learning_points,
#                 suggestions=suggestions,
#                 timestamp=datetime.now(),
#             )
#         except Exception as e:
#             return AgentResponse(
#                 agent_id=agent_id,
#                 agent_name=getattr(agent, "name", agent_id),
#                 content=f"[{agent_id}] æ‰§è¡Œå‡ºé”™: {e}",
#                 confidence=0.2,
#                 emotion="ğŸ˜…",
#                 learning_points=[],
#                 suggestions=[],
#                 timestamp=datetime.now(),
#             )


# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„å¤šæ™ºèƒ½ä½“åä½œç¼–æ’å™¨
ä¿®å¤åˆ†æ­§æ£€æµ‹é—®é¢˜ï¼Œå®ç°çœŸæ­£çš„æ™ºèƒ½ä½“åä½œ
"""
import asyncio
import logging
import re
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
from datetime import datetime
from collections import Counter

# å¯¼å…¥ç°æœ‰çš„æ™ºèƒ½ä½“
from ..agents.core_agents.tanaka_sensei import TanakaSensei
from ..agents.core_agents.koumi import KoumiAgent
from ..agents.core_agents.ai_analyzer import AIAnalyzer
from ..agents.core_agents.yamada_sensei import YamadaSensei
from ..agents.core_agents.sato_coach import SatoCoach
from ..agents.core_agents.mem_bot import MemBot


class CollaborationMode(Enum):
    DISCUSSION = "discussion"
    CORRECTION = "correction"
    CREATION = "creation"
    ANALYSIS = "analysis"


@dataclass
class AgentResponse:
    agent_id: str
    agent_name: str
    content: str
    confidence: float
    emotion: str
    learning_points: List[str]
    suggestions: List[str]
    timestamp: datetime
    agrees_with: Optional[List[str]] = None
    disagrees_with: Optional[List[str]] = None
    stance: Optional[str] = None  # æ–°å¢ï¼šè§‚ç‚¹ç«‹åœº


@dataclass
class DisagreementInfo:
    topic: str
    severity: str  # low, medium, high
    agents_involved: List[str]
    positions: Dict[str, str]
    evidence: Dict[str, List[str]]
    resolution_needed: bool


@dataclass
class CollaborationResult:
    responses: List[AgentResponse]
    consensus: Optional[str]
    conflicts: List[Tuple[str, str, str]]
    disagreements: List[DisagreementInfo]  # æ–°å¢è¯¦ç»†åˆ†æ­§ä¿¡æ¯
    final_recommendation: str
    user_arbitration_needed: bool
    session_id: str


class EnhancedMultiAgentOrchestrator:
    """å¢å¼ºçš„å¤šæ™ºèƒ½ä½“åä½œç¼–æ’å™¨ï¼Œä¸“é—¨è§£å†³åˆ†æ­§æ£€æµ‹é—®é¢˜"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.agents = {
            "tanaka": TanakaSensei(),
            "koumi": KoumiAgent(),
            "ai": AIAnalyzer(),
            "yamada": YamadaSensei(),
            "sato": SatoCoach(),
            "membot": MemBot(),
        }

        # æ™ºèƒ½ä½“ä¸“ä¸šå€¾å‘å’Œæ€§æ ¼ç‰¹å¾
        self.agent_profiles = {
            "tanaka": {
                "formality_preference": "formal",
                "strictness": "high",
                "primary_concern": "grammatical_accuracy",
                "typical_stance_keywords": ["æ­£ç¡®", "æ ‡å‡†", "è§„èŒƒ", "åº”è¯¥", "å¿…é¡»"]
            },
            "koumi": {
                "formality_preference": "casual",
                "strictness": "low",
                "primary_concern": "natural_communication",
                "typical_stance_keywords": ["è‡ªç„¶", "éšæ„", "å¯ä»¥", "æ²¡å…³ç³»", "è½»æ¾"]
            },
            "yamada": {
                "formality_preference": "traditional",
                "strictness": "medium",
                "primary_concern": "cultural_appropriateness",
                "typical_stance_keywords": ["ä¼ ç»Ÿ", "æ–‡åŒ–", "èƒŒæ™¯", "å†å²", "æ„ä¹‰"]
            },
            "ai": {
                "formality_preference": "analytical",
                "strictness": "data_driven",
                "primary_concern": "learning_effectiveness",
                "typical_stance_keywords": ["åˆ†æ", "æ•°æ®", "æ•ˆæœ", "ä¼˜åŒ–", "å»ºè®®"]
            },
            "sato": {
                "formality_preference": "goal_oriented",
                "strictness": "high",
                "primary_concern": "exam_success",
                "typical_stance_keywords": ["ç›®æ ‡", "è€ƒè¯•", "é‡è¦", "å¿…è¦", "ç­–ç•¥"]
            },
            "membot": {
                "formality_preference": "systematic",
                "strictness": "medium",
                "primary_concern": "retention_optimization",
                "typical_stance_keywords": ["è®°å¿†", "å¤ä¹ ", "ç³»ç»Ÿ", "è§„å¾‹", "å·©å›º"]
            }
        }

        # å¯¹ç«‹å…³é”®è¯æ£€æµ‹
        self.opposing_patterns = {
            "correctness": {
                "positive": ["æ­£ç¡®", "å¯¹çš„", "æ²¡é—®é¢˜", "å‡†ç¡®", "æ ‡å‡†"],
                "negative": ["é”™è¯¯", "ä¸å¯¹", "æœ‰é—®é¢˜", "ä¸å‡†ç¡®", "ä¸æ ‡å‡†"]
            },
            "permission": {
                "positive": ["å¯ä»¥", "èƒ½å¤Ÿ", "å…è®¸", "å»ºè®®ä½¿ç”¨"],
                "negative": ["ä¸å¯ä»¥", "ä¸èƒ½", "ä¸å…è®¸", "ä¸å»ºè®®"]
            },
            "necessity": {
                "positive": ["å¿…é¡»", "åº”è¯¥", "éœ€è¦", "é‡è¦"],
                "negative": ["ä¸å¿…", "ä¸åº”è¯¥", "ä¸éœ€è¦", "ä¸é‡è¦"]
            },
            "formality": {
                "formal": ["æ­£å¼", "æ•¬è¯­", "ç¤¼è²Œ", "è§„èŒƒ"],
                "casual": ["éšæ„", "å£è¯­", "éæ­£å¼", "è‡ªç„¶"]
            }
        }

    async def orchestrate_collaboration(
            self,
            user_input: str,
            active_agents: List[str],
            mode: CollaborationMode,
            session_context: Dict[str, Any],
    ) -> CollaborationResult:
        """ä¸»è¦åä½œç¼–æ’æ–¹æ³•"""
        session_id = session_context.get("session_id", f"session_{datetime.now().timestamp()}")

        self.logger.info(f"å¼€å§‹åä½œ: æ¨¡å¼={mode.value}, æ™ºèƒ½ä½“={active_agents}")

        # 1. è·å–æ‰€æœ‰æ™ºèƒ½ä½“çš„åˆå§‹å“åº”
        responses = await self._collect_agent_responses(user_input, active_agents, session_context)

        # 2. å¢å¼ºçš„åˆ†æ­§æ£€æµ‹
        disagreements = await self._detect_enhanced_disagreements(responses, user_input)

        # 3. å¦‚æœæœ‰åˆ†æ­§ï¼Œè¿›è¡Œç¬¬äºŒè½®äº¤å‰è¯„è®º
        if disagreements:
            cross_responses = await self._conduct_cross_evaluation(responses, disagreements, session_context)
            responses.extend(cross_responses)

        # 4. ç”Ÿæˆå†²çªåˆ—è¡¨ (å‘åå…¼å®¹)
        conflicts = self._convert_disagreements_to_conflicts(disagreements)

        # 5. å°è¯•å»ºç«‹å…±è¯†
        consensus = await self._build_consensus(responses, disagreements)

        # 6. ç”Ÿæˆæœ€ç»ˆå»ºè®®
        final_recommendation = await self._generate_final_recommendation(responses, disagreements, mode)

        # 7. åˆ¤æ–­æ˜¯å¦éœ€è¦ç”¨æˆ·ä»²è£
        needs_arbitration = any(d.severity in ["medium", "high"] for d in disagreements)

        return CollaborationResult(
            responses=responses,
            consensus=consensus,
            conflicts=conflicts,
            disagreements=disagreements,
            final_recommendation=final_recommendation,
            user_arbitration_needed=needs_arbitration,
            session_id=session_id,
        )

    async def _collect_agent_responses(self, user_input: str, active_agents: List[str],
                                       session_context: Dict[str, Any]) -> List[AgentResponse]:
        """æ”¶é›†æ‰€æœ‰æ™ºèƒ½ä½“çš„å“åº”"""
        tasks = [
            self._get_enhanced_agent_response(agent_id, user_input, session_context)
            for agent_id in active_agents
            if agent_id in self.agents
        ]

        raw_responses = await asyncio.gather(*tasks, return_exceptions=True)

        responses = []
        for r in raw_responses:
            if isinstance(r, AgentResponse):
                responses.append(r)
            elif isinstance(r, Exception):
                self.logger.error(f"æ™ºèƒ½ä½“å“åº”å¼‚å¸¸: {r}")

        return responses

    async def _get_enhanced_agent_response(self, agent_id: str, user_input: str,
                                           session_context: Dict[str, Any]) -> AgentResponse:
        """è·å–å¢å¼ºçš„æ™ºèƒ½ä½“å“åº”ï¼ˆåŒ…å«ç«‹åœºåˆ†æï¼‰"""
        agent = self.agents[agent_id]

        try:
            # è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†
            ret = await agent.process_user_input(
                user_input, session_context,
                scene=session_context.get("scene", "collaboration")
            )

            content = ret.get("content", str(ret))
            emotion = ret.get("emotion", "ğŸ™‚")
            learning_points = ret.get("learning_points", [])
            suggestions = ret.get("suggestions", [])

            # åˆ†æç«‹åœº
            stance = self._analyze_agent_stance(agent_id, content)

            # è®¡ç®—ç½®ä¿¡åº¦ (åŸºäºå†…å®¹é•¿åº¦å’Œå…³é”®è¯)
            confidence = self._calculate_confidence(content, agent_id)

            return AgentResponse(
                agent_id=agent_id,
                agent_name=getattr(agent, "name", agent_id),
                content=content,
                confidence=confidence,
                emotion=emotion,
                learning_points=learning_points,
                suggestions=suggestions,
                timestamp=datetime.now(),
                stance=stance
            )

        except Exception as e:
            self.logger.error(f"æ™ºèƒ½ä½“ {agent_id} å¤„ç†å¤±è´¥: {e}")
            return AgentResponse(
                agent_id=agent_id,
                agent_name=getattr(agent, "name", agent_id),
                content=f"[ç³»ç»Ÿé”™è¯¯] {agent_id} æ— æ³•å“åº”",
                confidence=0.1,
                emotion="ğŸ˜…",
                learning_points=[],
                suggestions=[],
                timestamp=datetime.now(),
                stance="error"
            )

    def _analyze_agent_stance(self, agent_id: str, content: str) -> str:
        """åˆ†ææ™ºèƒ½ä½“åœ¨å†…å®¹ä¸­çš„ç«‹åœº"""
        content_lower = content.lower()
        profile = self.agent_profiles.get(agent_id, {})

        # åŸºäºå¯¹ç«‹æ¨¡å¼æ£€æµ‹ç«‹åœº
        for pattern_type, patterns in self.opposing_patterns.items():
            for stance_type, keywords in patterns.items():
                if any(keyword in content_lower for keyword in keywords):
                    return f"{pattern_type}_{stance_type}"

        # åŸºäºæ™ºèƒ½ä½“æ€§æ ¼ç‰¹å¾
        if profile.get("formality_preference") == "formal" and any(
                word in content_lower for word in ["æ­£å¼", "è§„èŒƒ", "æ ‡å‡†"]):
            return "formal_strict"
        elif profile.get("formality_preference") == "casual" and any(
                word in content_lower for word in ["éšæ„", "è‡ªç„¶", "è½»æ¾"]):
            return "casual_flexible"

        return "neutral"

    def _calculate_confidence(self, content: str, agent_id: str) -> float:
        """è®¡ç®—å“åº”çš„ç½®ä¿¡åº¦"""
        base_confidence = 0.7

        # å†…å®¹é•¿åº¦å› å­
        length_factor = min(len(content) / 100, 1.0) * 0.2

        # ç¡®å®šæ€§å…³é”®è¯
        certainty_words = ["ç¡®å®", "è‚¯å®š", "ç»å¯¹", "æ˜ç¡®", "æ˜¾ç„¶"]
        uncertainty_words = ["å¯èƒ½", "ä¹Ÿè®¸", "å¤§æ¦‚", "ä¼¼ä¹", "æˆ–è®¸"]

        certainty_bonus = sum(0.05 for word in certainty_words if word in content)
        uncertainty_penalty = sum(0.05 for word in uncertainty_words if word in content)

        final_confidence = base_confidence + length_factor + certainty_bonus - uncertainty_penalty
        return max(0.1, min(1.0, final_confidence))

    async def _detect_enhanced_disagreements(self, responses: List[AgentResponse],
                                             user_input: str) -> List[DisagreementInfo]:
        """å¢å¼ºçš„åˆ†æ­§æ£€æµ‹ç®—æ³•"""
        disagreements = []

        # 1. è¯­ä¹‰å¯¹ç«‹æ£€æµ‹
        semantic_disagreements = self._detect_semantic_disagreements(responses)
        disagreements.extend(semantic_disagreements)

        # 2. ç«‹åœºå†²çªæ£€æµ‹
        stance_disagreements = self._detect_stance_conflicts(responses)
        disagreements.extend(stance_disagreements)

        # 3. ç½®ä¿¡åº¦å·®å¼‚æ£€æµ‹
        confidence_disagreements = self._detect_confidence_disagreements(responses)
        disagreements.extend(confidence_disagreements)

        # 4. ç‰¹å®šåœºæ™¯åˆ†æ­§æ£€æµ‹ï¼ˆé’ˆå¯¹æµ‹è¯•ç”¨ä¾‹ï¼‰
        scenario_disagreements = self._detect_scenario_specific_disagreements(responses, user_input)
        disagreements.extend(scenario_disagreements)

        return disagreements

    def _detect_semantic_disagreements(self, responses: List[AgentResponse]) -> List[DisagreementInfo]:
        """æ£€æµ‹è¯­ä¹‰å±‚é¢çš„å¯¹ç«‹è§‚ç‚¹"""
        disagreements = []

        for pattern_type, patterns in self.opposing_patterns.items():
            agent_positions = {}
            evidence = {}

            for response in responses:
                content = response.content.lower()
                agent_name = response.agent_name

                # æ£€æµ‹æ­£é¢å’Œè´Ÿé¢å…³é”®è¯
                positive_matches = [kw for kw in patterns.get("positive", []) if kw in content]
                negative_matches = [kw for kw in patterns.get("negative", []) if kw in content]

                if positive_matches and not negative_matches:
                    agent_positions[agent_name] = "positive"
                    evidence[agent_name] = positive_matches
                elif negative_matches and not positive_matches:
                    agent_positions[agent_name] = "negative"
                    evidence[agent_name] = negative_matches

            # æ£€æµ‹å¯¹ç«‹
            if self._has_opposing_positions(agent_positions):
                severity = self._calculate_disagreement_severity(agent_positions, evidence)
                disagreements.append(DisagreementInfo(
                    topic=f"{pattern_type}_opposition",
                    severity=severity,
                    agents_involved=list(agent_positions.keys()),
                    positions=agent_positions,
                    evidence=evidence,
                    resolution_needed=(severity != "low")
                ))

        return disagreements

    def _detect_stance_conflicts(self, responses: List[AgentResponse]) -> List[DisagreementInfo]:
        """æ£€æµ‹ç«‹åœºå†²çª"""
        disagreements = []
        stance_groups = {}

        # æŒ‰ç«‹åœºåˆ†ç»„
        for response in responses:
            if response.stance and response.stance != "neutral":
                if response.stance not in stance_groups:
                    stance_groups[response.stance] = []
                stance_groups[response.stance].append(response.agent_name)

        # æ£€æµ‹å†²çªç«‹åœº
        conflicting_pairs = [
            ("formal_strict", "casual_flexible"),
            ("correctness_positive", "correctness_negative"),
            ("permission_positive", "permission_negative")
        ]

        for stance1, stance2 in conflicting_pairs:
            if stance1 in stance_groups and stance2 in stance_groups:
                disagreements.append(DisagreementInfo(
                    topic=f"stance_conflict_{stance1}_vs_{stance2}",
                    severity="medium",
                    agents_involved=stance_groups[stance1] + stance_groups[stance2],
                    positions={**{agent: stance1 for agent in stance_groups[stance1]},
                               **{agent: stance2 for agent in stance_groups[stance2]}},
                    evidence={},
                    resolution_needed=True
                ))

        return disagreements

    def _detect_confidence_disagreements(self, responses: List[AgentResponse]) -> List[DisagreementInfo]:
        """æ£€æµ‹ç½®ä¿¡åº¦å·®å¼‚"""
        if len(responses) < 2:
            return []

        confidences = [r.confidence for r in responses]
        max_conf = max(confidences)
        min_conf = min(confidences)

        # å¦‚æœç½®ä¿¡åº¦å·®å¼‚è¶…è¿‡40%ï¼Œè®¤ä¸ºå­˜åœ¨åˆ†æ­§
        if max_conf - min_conf > 0.4:
            high_conf_agents = [r.agent_name for r in responses if r.confidence > 0.8]
            low_conf_agents = [r.agent_name for r in responses if r.confidence < 0.5]

            if high_conf_agents and low_conf_agents:
                return [DisagreementInfo(
                    topic="confidence_variance",
                    severity="medium",
                    agents_involved=high_conf_agents + low_conf_agents,
                    positions={
                        **{agent: "high_confidence" for agent in high_conf_agents},
                        **{agent: "low_confidence" for agent in low_conf_agents}
                    },
                    evidence={},
                    resolution_needed=True
                )]

        return []

    def _detect_scenario_specific_disagreements(self, responses: List[AgentResponse],
                                                user_input: str) -> List[DisagreementInfo]:
        """æ£€æµ‹ç‰¹å®šåœºæ™¯çš„åˆ†æ­§ï¼ˆé’ˆå¯¹æµ‹è¯•ç”¨ä¾‹è®¾è®¡ï¼‰"""
        disagreements = []

        # é’ˆå¯¹æµ‹è¯•ç”¨ä¾‹ï¼šæ•¬è¯­ä½¿ç”¨åˆ†æ­§
        if "ã¤ã‚‚ã‚Š" in user_input and any("ã§ã™" in r.content or "ã§ã‚ã‚‹" in r.content for r in responses):
            formal_agents = []
            casual_agents = []

            for response in responses:
                if "ã§ã™" in response.content or "æ•¬è¯­" in response.content:
                    formal_agents.append(response.agent_name)
                elif "ã¤ã‚‚ã‚Š" in response.content and "ã§ã™" not in response.content:
                    casual_agents.append(response.agent_name)

            if formal_agents and casual_agents:
                disagreements.append(DisagreementInfo(
                    topic="politeness_level_disagreement",
                    severity="medium",
                    agents_involved=formal_agents + casual_agents,
                    positions={
                        **{agent: "formal_required" for agent in formal_agents},
                        **{agent: "casual_acceptable" for agent in casual_agents}
                    },
                    evidence={},
                    resolution_needed=True
                ))

        # é’ˆå¯¹è‡ªç„¶åº¦åˆ¤æ–­åˆ†æ­§
        if "ã¨æ€ã„ã¾ã™" in user_input:
            natural_agents = []
            unnatural_agents = []

            for response in responses:
                if "è‡ªç„¶" in response.content or "é—®é¢˜" not in response.content:
                    natural_agents.append(response.agent_name)
                elif "ä¸è‡ªç„¶" in response.content or "å¥‡æ€ª" in response.content:
                    unnatural_agents.append(response.agent_name)

            if natural_agents and unnatural_agents:
                disagreements.append(DisagreementInfo(
                    topic="naturalness_assessment",
                    severity="medium",
                    agents_involved=natural_agents + unnatural_agents,
                    positions={
                        **{agent: "natural" for agent in natural_agents},
                        **{agent: "unnatural" for agent in unnatural_agents}
                    },
                    evidence={},
                    resolution_needed=True
                ))

        return disagreements

    def _has_opposing_positions(self, positions: Dict[str, str]) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯¹ç«‹è§‚ç‚¹"""
        values = list(positions.values())
        opposing_pairs = [
            ("positive", "negative"),
            ("formal", "casual"),
            ("necessary", "unnecessary")
        ]

        for pos1, pos2 in opposing_pairs:
            if pos1 in values and pos2 in values:
                return True
        return False

    def _calculate_disagreement_severity(self, positions: Dict[str, str],
                                         evidence: Dict[str, List[str]]) -> str:
        """è®¡ç®—åˆ†æ­§ä¸¥é‡ç¨‹åº¦"""
        num_agents = len(positions)
        num_positions = len(set(positions.values()))
        evidence_strength = sum(len(ev) for ev in evidence.values())

        if num_positions >= 3 or evidence_strength > 6:
            return "high"
        elif num_positions == 2 and num_agents >= 3:
            return "medium"
        else:
            return "low"

    async def _conduct_cross_evaluation(self, initial_responses: List[AgentResponse],
                                        disagreements: List[DisagreementInfo],
                                        session_context: Dict[str, Any]) -> List[AgentResponse]:
        """è¿›è¡Œäº¤å‰è¯„è®ºï¼ˆæ™ºèƒ½ä½“äº’ç›¸å›åº”ï¼‰"""
        cross_responses = []

        if not disagreements:
            return cross_responses

        # ä¸ºæ¯ä¸ªåˆ†æ­§é€‰æ‹©ä»£è¡¨æ€§æ™ºèƒ½ä½“è¿›è¡Œäº¤å‰è¯„è®º
        for disagreement in disagreements[:2]:  # é™åˆ¶ä¸ºå‰2ä¸ªåˆ†æ­§
            involved_agents = disagreement.agents_involved[:2]  # é™åˆ¶æ™ºèƒ½ä½“æ•°é‡

            for agent_name in involved_agents:
                # æ‰¾åˆ°å¯¹åº”çš„æ™ºèƒ½ä½“ID
                agent_id = self._get_agent_id_by_name(agent_name)
                if not agent_id:
                    continue

                # æ„å»ºäº¤å‰è¯„è®ºæç¤º
                other_views = [r.content[:100] for r in initial_responses
                               if r.agent_name != agent_name]

                if other_views:
                    cross_prompt = f"å…¶ä»–æ™ºèƒ½ä½“è®¤ä¸ºï¼š{'; '.join(other_views)}ã€‚è¯·å¯¹è¿™äº›è§‚ç‚¹è¿›è¡Œå›åº”ã€‚"

                    try:
                        cross_response = await self._get_enhanced_agent_response(
                            agent_id, cross_prompt, session_context
                        )
                        cross_response.content = f"[å›åº”] {cross_response.content}"
                        cross_responses.append(cross_response)
                    except Exception as e:
                        self.logger.error(f"äº¤å‰è¯„è®ºå¤±è´¥ {agent_id}: {e}")

        return cross_responses

    def _get_agent_id_by_name(self, agent_name: str) -> Optional[str]:
        """æ ¹æ®æ™ºèƒ½ä½“åç§°è·å–ID"""
        name_mapping = {
            "ç”°ä¸­å…ˆç”Ÿ": "tanaka",
            "å°ç¾": "koumi",
            "ã‚¢ã‚¤": "ai",
            "å±±ç”°å…ˆç”Ÿ": "yamada",
            "ä½è—¤æ•™ç»ƒ": "sato",
            "MemBot": "membot"
        }
        return name_mapping.get(agent_name)

    def _convert_disagreements_to_conflicts(self, disagreements: List[DisagreementInfo]) -> List[Tuple[str, str, str]]:
        """å°†åˆ†æ­§è½¬æ¢ä¸ºå†²çªæ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰"""
        conflicts = []

        for disagreement in disagreements:
            agents = disagreement.agents_involved
            if len(agents) >= 2:
                conflicts.append((
                    agents[0],
                    agents[1],
                    disagreement.topic
                ))

        return conflicts

    async def _build_consensus(self, responses: List[AgentResponse],
                               disagreements: List[DisagreementInfo]) -> Optional[str]:
        """å°è¯•å»ºç«‹å…±è¯†"""
        if not disagreements:
            return "æ™ºèƒ½ä½“ä»¬åŸºæœ¬è¾¾æˆä¸€è‡´æ„è§ã€‚"

        # ç»Ÿè®¡ä¸»è¦è§‚ç‚¹
        main_points = []
        for response in responses:
            if response.confidence > 0.7:
                main_points.append(f"{response.agent_name}: {response.content[:50]}...")

        disagreement_summary = f"å‘ç°{len(disagreements)}ä¸ªåˆ†æ­§ç‚¹"
        consensus = f"ä¸»è¦è§‚ç‚¹åŒ…æ‹¬ï¼š{'; '.join(main_points[:3])}ã€‚{disagreement_summary}ï¼Œå»ºè®®ç»¼åˆè€ƒè™‘ã€‚"

        return consensus

    async def _generate_final_recommendation(self, responses: List[AgentResponse],
                                             disagreements: List[DisagreementInfo],
                                             mode: CollaborationMode) -> str:
        """ç”Ÿæˆæœ€ç»ˆå»ºè®®"""
        if not responses:
            return "æœªè·å¾—æœ‰æ•ˆå›å¤ï¼Œå»ºè®®é‡æ–°æé—®ã€‚"

        # é€‰æ‹©æœ€é«˜ç½®ä¿¡åº¦çš„å›å¤ä½œä¸ºåŸºç¡€
        best_response = max(responses, key=lambda r: r.confidence)

        recommendation = f"åŸºäº{len(responses)}ä¸ªæ™ºèƒ½ä½“çš„åä½œåˆ†æï¼Œ"

        if disagreements:
            recommendation += f"å‘ç°{len(disagreements)}ä¸ªåˆ†æ­§ç‚¹ï¼Œ"
            recommendation += f"å»ºè®®é‡ç‚¹è€ƒè™‘{best_response.agent_name}çš„è§‚ç‚¹ï¼š{best_response.content[:100]}"
        else:
            recommendation += f"æ™ºèƒ½ä½“ä»¬åŸºæœ¬ä¸€è‡´ï¼Œæ¨èé‡‡çº³ï¼š{best_response.content[:150]}"

        return recommendation


# ä¿æŒå‘åå…¼å®¹çš„åŸå§‹ç±»
class MultiAgentOrchestrator(EnhancedMultiAgentOrchestrator):
    """å‘åå…¼å®¹çš„åŸå§‹åä½œç¼–æ’å™¨"""
    pass