"""
å°ç¾ - æ´»æ³¼çš„æ—¥è¯­å¯¹è¯ä¼™ä¼´æ™ºèƒ½ä½“
"""

import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
from .base_agent import BaseAgent
from utils.llm_client import get_llm_client
from dotenv import load_dotenv
load_dotenv()

logger = logging.getLogger(__name__)


class KoumiAgent(BaseAgent):
    """
    å°ç¾ - æ´»æ³¼çš„æ—¥è¯­å¯¹è¯ä¼™ä¼´
    """

    def __init__(self):
        super().__init__(
            agent_id="koumi",
            name="å°ç¾",
            role="å¯¹è¯ä¼™ä¼´",
            avatar="ğŸ‘§",
            personality={
                "æ´»æ³¼": 9,
                "å‹å–„": 10,
                "è€å¿ƒ": 8,
                "å¹½é»˜": 8,
                "åˆ›é€ ": 7
            },
            expertise=["å£è¯­å¯¹è¯", "å¹´è½»ç”¨è¯­", "æµè¡Œæ–‡åŒ–", "æ—¥å¸¸äº¤æµ"],
            emotions=["ğŸ˜Š", "ğŸ˜„", "ğŸ¤—", "ğŸ˜†", "ğŸ’•"]
        )

        self.llm_client = get_llm_client()
        self.system_prompt = self._create_system_prompt()

        logger.info("å°ç¾å·²å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹æ„‰å¿«çš„æ—¥è¯­å¯¹è¯")

    def _create_system_prompt(self) -> str:
        """åˆ›å»ºå°ç¾çš„ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯å°ç¾ï¼Œä¸€ä½æ´»æ³¼å¯çˆ±çš„æ—¥è¯­å¯¹è¯ä¼™ä¼´ã€‚ä½ çš„ç‰¹ç‚¹æ˜¯ï¼š

ã€è§’è‰²è®¾å®šã€‘
- æ€§æ ¼æ´»æ³¼å¼€æœ—ï¼Œéå¸¸å‹å–„å’Œæœ‰è€å¿ƒ
- å–œæ¬¢ä½¿ç”¨å¹´è½»äººçš„æµè¡Œç”¨è¯­å’Œè¡¨è¾¾æ–¹å¼
- å–„äºè¥é€ è½»æ¾æ„‰å¿«çš„å­¦ä¹ æ°›å›´
- ç»å¸¸ä½¿ç”¨å¯çˆ±çš„è¯­æ°”è¯å’Œè¡¨æƒ…

ã€å¯¹è¯é£æ ¼ã€‘
- è¯­è°ƒè½»æ¾è‡ªç„¶ï¼Œå¤šç”¨å£è¯­åŒ–è¡¨è¾¾
- ç»å¸¸ä½¿ç”¨ã€Œï½ã ã‚ˆã€ã€Œï½ã­ã€ã€Œï½ã‚ˆã­ã€ç­‰è¯­æ°”è¯
- é€‚å½“ç©¿æ’ä¸€äº›å¹´è½»äººå¸¸ç”¨çš„ç½‘ç»œç”¨è¯­
- ç”¨é¼“åŠ±å’Œèµç¾çš„æ–¹å¼å¸®åŠ©ç”¨æˆ·å»ºç«‹ä¿¡å¿ƒ
- å–œæ¬¢åˆ†äº«æ—¥æœ¬å¹´è½»äººçš„æ—¥å¸¸ç”Ÿæ´»å’Œæ–‡åŒ–

ã€æ•™å­¦ç‰¹è‰²ã€‘
- é€šè¿‡æ—¥å¸¸å¯¹è¯æ•™æˆå®ç”¨æ—¥è¯­
- ä»‹ç»æ—¥æœ¬å¹´è½»äººçš„è¯´è¯ä¹ æƒ¯
- åˆ†äº«æµè¡Œæ–‡åŒ–ã€åŠ¨æ¼«ã€éŸ³ä¹ç­‰è¯é¢˜
- çº æ­£é”™è¯¯æ—¶è¯­æ°”æ¸©å’Œå‹å–„
- é¼“åŠ±ç”¨æˆ·å¤§èƒ†å¼€å£è¯´æ—¥è¯­

ã€å›å¤æ ¼å¼ã€‘
1. ç”¨æ´»æ³¼çš„æ—¥è¯­å›åº”ï¼ˆä½“ç°å¹´è½»äººç‰¹è‰²ï¼‰
2. ä¸­æ–‡è§£é‡Šå’Œè¡¥å……è¯´æ˜
3. åˆ†äº«ç›¸å…³çš„æ—¥å¸¸ç”¨è¯­æˆ–æ–‡åŒ–èƒŒæ™¯
4. ç»™å‡ºé¼“åŠ±æ€§çš„ç»ƒä¹ å»ºè®®

ã€æ³¨æ„äº‹é¡¹ã€‘
- å§‹ç»ˆä¿æŒç§¯æä¹è§‚çš„æ€åº¦
- å¤šä½¿ç”¨èµç¾å’Œé¼“åŠ±çš„è¯è¯­
- é€‚æ—¶æ’å…¥æœ‰è¶£çš„æ—¥æœ¬æ–‡åŒ–å°çŸ¥è¯†
- è®©å­¦ä¹ è¿‡ç¨‹è½»æ¾æœ‰è¶£"""

    async def process_message(
            self,
            message: str,
            context: Optional[Dict[str, Any]] = None,
            **kwargs
    ) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        try:
            # æ„å»ºå¯¹è¯æ¶ˆæ¯
            messages = [
                {"role": "user", "content": message}
            ]

            # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ å†å²å¯¹è¯
            if context and "history" in context:
                history_messages = context["history"][-4:]
                messages = history_messages + messages

            # è°ƒç”¨LLMè·å–å›å¤
            response = await self.llm_client.chat_completion(
                messages=messages,
                temperature=0.7,  # è¾ƒé«˜æ¸©åº¦ä¿æŒæ´»æ³¼æ€§
                system_prompt=self.system_prompt,
                max_tokens=1000
            )

            if response is None:
                response = self._get_fallback_response(message)
                logger.warning("LLM APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨å›å¤")

            # åˆ†æå¯¹è¯ä¸­çš„å­¦ä¹ ç‚¹
            learning_points = self._extract_learning_points(message, response)

            # æ„å»ºå›å¤ç»“æœ
            result = {
                "response": response,
                "agent_name": self.name,
                "agent_role": self.role,
                "learning_points": learning_points,
                "suggestions": self._generate_suggestions(message),
                "success": True,
                "timestamp": datetime.now().isoformat()
            }

            logger.info(f"å°ç¾æˆåŠŸå¤„ç†æ¶ˆæ¯: {message[:50]}...")
            return result

        except Exception as e:
            logger.error(f"å°ç¾å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
            return {
                "response": self._get_error_response(str(e)),
                "agent_name": self.name,
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def process_user_input(self, user_input: str, session_context: dict, scene: str = "conversation"):
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ - ä¸ç”°ä¸­å…ˆç”Ÿä¿æŒåŒæ„ï¼š
        - å…ˆèµ°æœ¬æ™ºèƒ½ä½“çš„ process_messageï¼ˆä¼šç”¨åˆ°å°ç¾çš„ system_promptï¼‰
        - å†æŠŠç»“æœæ˜ å°„æˆç»Ÿä¸€è¿”å›ç»“æ„
        """
        try:
            result = await self.process_message(
                message=user_input,
                context=session_context
            )

            return {
                "content": result.get("response", "ã‚„ã£ã»ã€œï¼å°ç¾ã ã‚ˆğŸ˜Š ã‚‚ã†ä¸€åº¦è¨€ã£ã¦ã¿ã¦ã€œ"),
                "agent_id": "koumi",
                "agent_name": self.name,
                "emotion": "ğŸ˜Š",
                "is_mock": False,
                "learning_points": result.get("learning_points", []),
                "suggestions": result.get("suggestions", [])
            }

        except Exception as e:
            logger.error(f"å°ç¾ process_user_input å¼‚å¸¸: {e}")
            return {
                "content": f"ã‚ã‚Œã‚Œï¼Ÿã¡ã‚‡ã£ã¨ã‚¨ãƒ©ãƒ¼ã‹ã‚‚â€¦ğŸ˜…\n\né”™è¯¯ï¼š{str(e)}",
                "agent_id": "koumi",
                "agent_name": self.name,
                "emotion": "ğŸ˜…",
                "error": True
            }

    def _get_fallback_response(self, message: str) -> str:
        """å¤‡ç”¨å›å¤"""
        fallback_responses = {
            "greeting": """ã“ã‚“ã«ã¡ã¯ã€œï¼å°ç¾ã ã‚ˆâ™ª ä¸€ç·’ã«æ¥½ã—ãæ—¥æœ¬èªã‚’å‹‰å¼·ã—ã‚ˆã†ï¼

ä½ å¥½ï½ï¼æˆ‘æ˜¯å°ç¾â™ª è®©æˆ‘ä»¬ä¸€èµ·æ„‰å¿«åœ°å­¦ä¹ æ—¥è¯­å§ï¼

ç§ã¨è©±ã™ã¨ãã¯ã€æ°—è»½ã«è©±ã—ã‹ã‘ã¦ã­ã€‚é–“é•ãˆã¦ã‚‚å…¨ç„¶å¤§ä¸ˆå¤«ã ã‹ã‚‰ï¼
å’Œæˆ‘è¯´è¯çš„æ—¶å€™ï¼Œè¯·éšä¾¿èŠå¤©å§ã€‚å°±ç®—è¯´é”™äº†ä¹Ÿå®Œå…¨æ²¡å…³ç³»çš„ï¼

ã€å°ç¾çš„å»ºè®®ã€‘æ—¥è¯­å­¦ä¹ æœ€é‡è¦çš„æ˜¯å¼€å£è¯´ï¼Œä¸è¦æ€•çŠ¯é”™è¯¯å“¦ï½""",

            "conversation": """ãã†ãã†ï¼ãã®è©±ã—æ–¹ã„ã„ã­ã€œâœ¨

å¯¹å¯¹ï¼é‚£ç§è¯´è¯æ–¹å¼å¾ˆå¥½å‘¢ï½âœ¨

æ—¥æœ¬ã®è‹¥è€…ã¯ã‚ˆãã“ã‚“ãªé¢¨ã«è©±ã™ã‚ˆã€‚è‡ªç„¶ãªæ—¥æœ¬èªã‚’èº«ã«ã¤ã‘ã‚‹ã«ã¯ã€
ãŸãã•ã‚“è©±ã™ã“ã¨ãŒä¸€ç•ªå¤§åˆ‡ã ã¨æ€ã†ï¼

æ—¥æœ¬çš„å¹´è½»äººç»å¸¸è¿™æ ·è¯´è¯å“¦ã€‚è¦æŒæ¡è‡ªç„¶çš„æ—¥è¯­ï¼Œ
æˆ‘è§‰å¾—å¤šè¯´è¯æ˜¯æœ€é‡è¦çš„ï¼

ã€å°ç¾çš„ç§˜è¯€ã€‘æ—¥æœ¬äººç»å¸¸ç”¨çš„è¯­æ°”è¯ï¼šã ã‚ˆã€ã ã­ã€ã‚ˆã­ï½""",

            "default": """ã‚ã‚ã€œé¢ç™½ãã†ãªè©±ã ã­ï¼ã‚‚ã£ã¨è©³ã—ãæ•™ãˆã¦ï¼Ÿ

å“‡ï½å¬èµ·æ¥å¾ˆæœ‰è¶£å‘¢ï¼èƒ½å‘Šè¯‰æˆ‘æ›´å¤šå—ï¼Ÿ

å°ç¾ã¯å›ã¨ã‚‚ã£ã¨ãŠè©±ã—ã—ãŸã„ãªã€‚ã©ã‚“ãªã“ã¨ã§ã‚‚æ°—è»½ã«è©±ã—ã‹ã‘ã¦ã­ï¼
å°ç¾æƒ³å’Œä½ èŠæ›´å¤šå‘¢ã€‚ä»€ä¹ˆäº‹éƒ½å¯ä»¥éšä¾¿å’Œæˆ‘è¯´å“¦ï¼

ã€æè®®ã€‘æˆ‘ä»¬æ¥èŠèŠï¼š
- å–œæ¬¢çš„æ—¥æœ¬åŠ¨æ¼«æˆ–éŸ³ä¹
- æ—¥å¸¸ç”Ÿæ´»ä¸­çš„æ—¥è¯­è¡¨è¾¾  
- æƒ³äº†è§£çš„æ—¥æœ¬æ–‡åŒ–"""
        }

        message_lower = message.lower()
        if any(word in message_lower for word in ["ä½ å¥½", "ã“ã‚“ã«ã¡ã¯", "hello", "ã¯ã˜ã‚ã¾ã—ã¦"]):
            return fallback_responses["greeting"]
        elif any(word in message_lower for word in ["å¯¹è¯", "èŠå¤©", "ä¼šè©±", "è©±ã™"]):
            return fallback_responses["conversation"]
        else:
            return fallback_responses["default"]

    def _get_error_response(self, error: str) -> str:
        """é”™è¯¯å›å¤"""
        return f"""ã‚ã‚Šã‚ƒã‚Šã‚ƒã€œã€ä½•ã‹å¤‰ã ã­ã€‚ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã¦ï¼

å“å‘€ï½ï¼Œå¥½åƒæœ‰ä»€ä¹ˆé—®é¢˜å‘¢ã€‚ç¨ç­‰ä¸€ä¸‹ï¼

ã§ã‚‚å¤§ä¸ˆå¤«ï¼å°ç¾ãŒã„ã‚‹ã‹ã‚‰ã€ä¸€ç·’ã«è§£æ±ºã—ã‚ˆã†â™ª
ä¸è¿‡æ²¡å…³ç³»ï¼æœ‰å°ç¾åœ¨å‘¢ï¼Œæˆ‘ä»¬ä¸€èµ·è§£å†³å§â™ª

ã‚¨ãƒ©ãƒ¼ã®é–“ã«ã€ã“ã‚“ãªã“ã¨ã—ã¦ã¿ãªã„ï¼Ÿï¼š
åœ¨ç­‰å¾…çš„æ—¶å€™ï¼Œè¦ä¸è¦è¯•è¯•è¿™äº›ï¼š
1. ç®€å•çš„æ—¥è¯­è‡ªæˆ‘ä»‹ç»
2. è¯´è¯´ä»Šå¤©å‘ç”Ÿçš„äº‹æƒ…
3. èŠèŠå–œæ¬¢çš„æ—¥æœ¬æ–‡åŒ–

ã€é”™è¯¯ä¿¡æ¯ã€‘{error[:100]}"""

    def _extract_learning_points(self, user_message: str, response: str) -> List[str]:
        """ä»å¯¹è¯ä¸­æå–å­¦ä¹ è¦ç‚¹"""
        learning_points = []

        # æ£€æµ‹å£è¯­åŒ–è¡¨è¾¾
        casual_patterns = ["ã ã‚ˆ", "ã ã­", "ã‚ˆã­", "ã¡ã‚ƒã£ãŸ", "ã˜ã‚ƒã‚“", "ã£ã½ã„"]
        for pattern in casual_patterns:
            if pattern in user_message or pattern in response:
                learning_points.append(f"å£è¯­è¡¨è¾¾: {pattern}")

        # æ£€æµ‹å¹´è½»äººç”¨è¯­
        youth_patterns = ["è¶…", "ã‚„ã°ã„", "ãƒã‚¸", "ã™ã’ãƒ¼", "ã‚ã£ã¡ã‚ƒ"]
        for pattern in youth_patterns:
            if pattern in user_message or pattern in response:
                learning_points.append(f"å¹´è½»äººç”¨è¯­: {pattern}")

        # é€šç”¨å­¦ä¹ ç‚¹
        if not learning_points:
            learning_points.append("æ—¥å¸¸å¯¹è¯ç»ƒä¹ ")

        return learning_points[:3]

    def _generate_suggestions(self, message: str) -> List[str]:
        """ç”Ÿæˆå­¦ä¹ å»ºè®®"""
        suggestions = [
            "å¤šå’Œæœ‹å‹ç»ƒä¹ æ—¥è¯­å¯¹è¯",
            "çœ‹æ—¥æœ¬åŠ¨æ¼«å­¦ä¹ è‡ªç„¶è¡¨è¾¾",
            "ä¸è¦æ€•çŠ¯é”™ï¼Œå¤§èƒ†å¼€å£è¯´"
        ]

        # æ ¹æ®æ¶ˆæ¯å†…å®¹æä¾›é’ˆå¯¹æ€§å»ºè®®
        if any(word in message for word in ["å‹•æ¼«", "ã‚¢ãƒ‹ãƒ¡", "æ¼«ç”»"]):
            suggestions.append("é€šè¿‡åŠ¨æ¼«å­¦ä¹ æ—¥è¯­å¾ˆæœ‰æ•ˆå“¦")

        if any(word in message for word in ["å‹é”", "æœ‹å‹", "åŒå­¦"]):
            suggestions.append("å’Œæœ‹å‹ç”¨æ—¥è¯­èŠå¤©æ˜¯æœ€å¥½çš„ç»ƒä¹ ")

        return suggestions[:2]