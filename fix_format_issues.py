#!/usr/bin/env python3
"""
ä¸€é”®æ ¼å¼ä¿®å¤è„šæœ¬ - è§£å†³æ‰€æœ‰ç¼©è¿›å’Œæ¢è¡Œé—®é¢˜
"""


def fix_base_agent():
    """ä¿®å¤ base_agent.py"""
    content = '''"""æ™ºèƒ½ä½“åŸºç±»"""
from abc import ABC, abstractmethod
from typing import Dict, Any, List
from datetime import datetime

from src.data.models.agent import Agent, AgentResponse
from src.utils.logger import setup_logger


class BaseAgent(ABC):
    """æ™ºèƒ½ä½“åŸºç±»"""

    def __init__(self, config: Agent):
        self.config = config
        self.logger = setup_logger(f"agent_{config.name}")
        self.conversation_history: List[Dict[str, Any]] = []
        self.state: Dict[str, Any] = {}

    @abstractmethod
    async def process_message(self, message: str, 
                            context: Dict[str, Any] = None) -> AgentResponse:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶è¿”å›å“åº”"""
        pass

    @abstractmethod
    def get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        pass

    def add_to_history(self, role: str, content: str, 
                      metadata: Dict[str, Any] = None):
        """æ·»åŠ å¯¹è¯å†å²"""
        self.conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now(),
            "metadata": metadata or {}
        })

    def get_personality_trait(self, trait: str) -> int:
        """è·å–æ€§æ ¼ç‰¹å¾"""
        return getattr(self.config.personality, trait, 5)

    async def _create_response(self, content: str, confidence: float = 0.8, 
                             metadata: Dict[str, Any] = None) -> AgentResponse:
        """åˆ›å»ºæ ‡å‡†å“åº”"""
        return AgentResponse(
            agent_id=self.config.id,
            content=content,
            confidence=confidence,
            metadata=metadata or {}
        )
'''

    with open("src/core/agents/base_agent.py", "w", encoding="utf-8") as f:
        f.write(content)
    print("âœ… ä¿®å¤äº† base_agent.py")


def fix_tanaka():
    """ä¿®å¤ tanaka.py çš„ç¼©è¿›é—®é¢˜"""
    # è¯»å–ç°æœ‰å†…å®¹
    with open("src/core/agents/core_agents/tanaka.py", "r", encoding="utf-8") as f:
        content = f.read()

    # ä¿®å¤ç‰¹å®šè¡Œçš„ç¼©è¿›é—®é¢˜
    lines = content.split('\n')

    # æ‰¾åˆ°å¹¶ä¿®å¤ process_message æ–¹æ³•çš„ç¼©è¿›
    for i, line in enumerate(lines):
        if "async def process_message(self, message: str," in line:
            lines[i + 1] = "                            context: Dict[str, Any] = None) -> AgentResponse:"
        elif "response_content = self._create_correction_response(" in line:
            lines[i + 1] = "                    message, grammar_issues)"
        elif "return f\"ç´ æ™´ã‚‰ã—ã„æ–‡ç« ã§ã™ã­ï¼ã€Œ{message}ã€ã¨ã„ã†è¡¨ç¾ã¯æ­£ç¢ºã§è‡ªç„¶ã§ã™ã€‚ã“ã®èª¿å­ã§é ‘å¼µã£ã¦ãã ã•ã„ï¼\"" in line:
            lines[i] = "            return f\"ç´ æ™´ã‚‰ã—ã„æ–‡ç« ã§ã™ã­ï¼ã€Œ{message}ã€ã¨ã„ã†è¡¨ç¾ã¯æ­£ç¢ºã§è‡ªç„¶ã§ã™ã€‚ã“ã®èª¿å­ã§é ‘å¼µã£ã¦ãã ã•ã„ï¼\""

    # ç¡®ä¿æ–‡ä»¶ä»¥æ¢è¡Œç¬¦ç»“å°¾
    content = '\n'.join(lines)
    if not content.endswith('\n'):
        content += '\n'

    with open("src/core/agents/core_agents/tanaka.py", "w", encoding="utf-8") as f:
        f.write(content)
    print("âœ… ä¿®å¤äº† tanaka.py")


def fix_models():
    """ä¿®å¤æ•°æ®æ¨¡å‹æ–‡ä»¶"""

    # ä¿®å¤ base.py
    base_content = '''"""åŸºç¡€æ•°æ®æ¨¡å‹"""
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional
import uuid


@dataclass
class BaseEntity:
    """åŸºç¡€å®ä½“æ¨¡å‹"""
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: Optional[datetime] = None


@dataclass
class AgentPersonality:
    """æ™ºèƒ½ä½“æ€§æ ¼é…ç½®"""
    strictness: int = 5  # 1-10
    humor: int = 5       # 1-10
    patience: int = 5    # 1-10
    creativity: int = 5  # 1-10
    formality: int = 5   # 1-10


@dataclass
class MessageMetadata:
    """æ¶ˆæ¯å…ƒæ•°æ®"""
    confidence: float = 0.8
    processing_time: float = 0.0
    token_count: int = 0
    cost: Optional[float] = None
'''

    with open("src/data/models/base.py", "w", encoding="utf-8") as f:
        f.write(base_content)
    print("âœ… ä¿®å¤äº† base.py")

    # ä¿®å¤ agent.py
    agent_content = '''"""æ™ºèƒ½ä½“æ•°æ®æ¨¡å‹"""
from dataclasses import dataclass, field
from typing import List, Dict, Any
from .base import BaseEntity, AgentPersonality


@dataclass
class Agent(BaseEntity):
    """æ™ºèƒ½ä½“æ¨¡å‹"""
    name: str = ""
    description: str = ""
    personality: AgentPersonality = field(default_factory=AgentPersonality)
    expertise_areas: List[str] = field(default_factory=list)
    system_prompt: str = ""
    is_active: bool = True
    custom_config: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AgentResponse(BaseEntity):
    """æ™ºèƒ½ä½“å“åº”æ¨¡å‹"""
    agent_id: str = ""
    content: str = ""
    confidence: float = 0.8
    metadata: Dict[str, Any] = field(default_factory=dict)
'''

    with open("src/data/models/agent.py", "w", encoding="utf-8") as f:
        f.write(agent_content)
    print("âœ… ä¿®å¤äº† agent.py")


def fix_config():
    """ä¿®å¤ config.py"""
    content = '''"""åº”ç”¨ç¨‹åºé…ç½®ç®¡ç†"""
from dataclasses import dataclass
from typing import Optional
from pathlib import Path
import os


@dataclass  
class Settings:
    """åº”ç”¨ç¨‹åºè®¾ç½®"""
    app_name: str = "Japanese Learning Multi-Agent System"
    debug: bool = False
    version: str = "0.1.0"
    database_url: str = "sqlite:///./japanese_learning.db"
    openai_api_key: Optional[str] = None
    model_name: str = "gpt-3.5-turbo"
    max_tokens: int = 1000
    temperature: float = 0.7
    data_dir: Path = Path("./data")
    logs_dir: Path = Path("./logs")

    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.debug = os.getenv('DEBUG', 'False').lower() == 'true'
        self.data_dir.mkdir(exist_ok=True)
        self.logs_dir.mkdir(exist_ok=True)


settings = Settings()
'''

    with open("src/utils/config.py", "w", encoding="utf-8") as f:
        f.write(content)
    print("âœ… ä¿®å¤äº† config.py")


def fix_logger():
    """ä¿®å¤ logger.py"""
    content = '''"""æ—¥å¿—ç®¡ç†æ¨¡å—"""
import logging
import sys
from pathlib import Path
from datetime import datetime


def setup_logger(name: str = "japanese_learning", 
                level: str = "INFO") -> logging.Logger:
    """è®¾ç½®æ—¥å¿—å™¨"""

    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, level.upper()))

    # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
    if logger.handlers:
        return logger

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)

    # æ–‡ä»¶å¤„ç†å™¨
    log_file = Path("logs") / f"{name}_{datetime.now().strftime('%Y%m%d')}.log"
    log_file.parent.mkdir(exist_ok=True)
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)

    # æ ¼å¼å™¨
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    console_handler.setFormatter(formatter)
    file_handler.setFormatter(formatter)

    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

    return logger


# é»˜è®¤æ—¥å¿—å™¨
logger = setup_logger()
'''

    with open("src/utils/logger.py", "w", encoding="utf-8") as f:
        f.write(content)
    print("âœ… ä¿®å¤äº† logger.py")


def main():
    """æ‰§è¡Œæ‰€æœ‰ä¿®å¤"""
    print("ğŸ”§ å¼€å§‹ä¿®å¤æ‰€æœ‰æ ¼å¼é—®é¢˜...")

    fix_base_agent()
    fix_tanaka()
    fix_models()
    fix_config()
    fix_logger()

    print("\nâœ… æ‰€æœ‰æ ¼å¼é—®é¢˜ä¿®å¤å®Œæˆï¼")
    print("ç°åœ¨è¿è¡Œæ£€æŸ¥:")
    print("python -m flake8 src/ --max-line-length=100 --ignore=E203,W503")


if __name__ == "__main__":
    main()